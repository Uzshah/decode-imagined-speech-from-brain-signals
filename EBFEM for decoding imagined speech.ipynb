{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e52d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import utils\n",
    "import numpy as np\n",
    "from models import models\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce2032be",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = utils()\n",
    "m = models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "191e601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, channels = u.extract_all()\n",
    "x_test, y_test, channels = u.extract_all(subset=\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2611a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_names=list(channels.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee08a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4500, 64, 795), (750, 64, 795))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16653c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rythm(rythm, x_train, y_train, x_test, y_test, features = \"statistics\"):\n",
    "    x_train = u.get_ryhtm(x_train, rythm)\n",
    "    x_test = u.get_ryhtm(x_test, rythm)\n",
    "    \n",
    "    print(\"statical features extraction start\")\n",
    "    x_train_temp = np.asarray([u.temporal_features(raw, counter=idx) for idx, raw in enumerate(x_train)])\n",
    "    x_test_temp = np.asarray([u.temporal_features(raw, counter=idx) for idx, raw in enumerate(x_test)])\n",
    "    print(\"statical features extraction complete\")\n",
    "    print(\"temporal features extraction start\")\n",
    "    x_train_stat = np.asarray([u.statistical_features(raw, counter=idx) for idx, raw in enumerate(x_train)])\n",
    "    x_test_stat = np.asarray([u.statistical_features(raw, counter=idx) for idx, raw in enumerate(x_test)])\n",
    "    print(\"temporal features extraction end\")\n",
    "    print(\"spectral features extraction start\")\n",
    "    x_train_spect = np.asarray([u.spectral_features(raw, counter=idx) for idx, raw in enumerate(x_train)])\n",
    "    x_test_spect = np.asarray([u.spectral_features(raw, counter=idx) for idx, raw in enumerate(x_test)])\n",
    "    print(\"spectral features extraction end\")\n",
    "    \n",
    "    return x_train_temp, x_test_temp, x_train_stat, x_test_stat, x_train_spect, x_test_spect\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac4b9577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statical features extraction start\n",
      "Trail  0\n",
      "Trail  1000\n",
      "Trail  2000\n",
      "Trail  3000\n",
      "Trail  4000\n",
      "Trail  0\n",
      "statical features extraction complete\n",
      "temporal features extraction start\n",
      "Trail  0\n",
      "Trail  1000\n",
      "Trail  2000\n",
      "Trail  3000\n",
      "Trail  4000\n",
      "Trail  0\n",
      "temporal features extraction end\n",
      "spectral features extraction start\n",
      "Trail  0\n",
      "Trail  1000\n",
      "Trail  2000\n",
      "Trail  3000\n",
      "Trail  4000\n",
      "Trail  0\n",
      "spectral features extraction end\n"
     ]
    }
   ],
   "source": [
    "x_train_temp, x_test_temp, x_train_stat, x_test_stat, x_train_spect, x_test_spect = check_rythm(\"delta\", x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2076132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_arr(testlist):\n",
    "    output = list()\n",
    "    for i in testlist:\n",
    "        if isinstance(i, float)==False and isinstance(i, int)==False:\n",
    "            output.extend(i)\n",
    "        else:\n",
    "            output.append(i)\n",
    "    return output\n",
    "x_train_spect = np.array([flatten_arr(feat) for feat in x_train_spect])\n",
    "x_test_spect = np.array([flatten_arr(feat) for feat in -x_test_spect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a8ebfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_stat_temp = np.hstack((x_train_stat, x_train_temp))\n",
    "x_test_stat_temp = np.hstack((x_test_stat, x_test_temp))\n",
    "x_train_stat_spect = np.hstack((x_train_stat, x_train_spect))\n",
    "x_test_stat_spect = np.hstack((x_test_stat, x_test_spect))\n",
    "x_train_temp_spect = np.hstack((x_train_temp, x_train_spect))\n",
    "x_test_temp_spect = np.hstack((x_test_temp, x_test_spect))\n",
    "x_train_all_features = np.hstack((x_train_stat, x_train_temp, x_train_spect))\n",
    "x_test_all_features = np.hstack((x_test_stat, x_test_temp, x_test_spect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91066657",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = [\"x_train_temp\", \"x_test_temp\", \"x_train_stat\", \"x_test_stat\", \"x_train_spect\", \"x_test_spect\",\n",
    "       \"x_train_stat_temp\", \"x_test_stat_temp\", \"x_train_stat_spect\", \"x_test_stat_spect\", \"x_train_temp_spect\",\n",
    "       \"x_test_temp_spect\", \"x_train_all_features\", \"x_test_all_features\"]\n",
    "t = [x_train_temp, x_test_temp, x_train_stat, x_test_stat, x_train_spect, x_test_spect,x_train_stat_temp, \n",
    "     x_test_stat_temp, x_train_stat_spect, x_test_stat_spect, x_train_temp_spect,x_test_temp_spect, \n",
    "     x_train_all_features, x_test_all_features]\n",
    "# for filename, data in zip(ttt, t):\n",
    "#     filen = filename+\".npy\"\n",
    "#     with open(filen, 'wb') as f:\n",
    "#         np.save(f, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dd8ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def knnclf(x_train, y_train, x_test, y_test):\n",
    "    kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "    kclf.fit(x_train, y_train)\n",
    "    y_pred = kclf.predict(x_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\n -------------Classification Report-------------\\n\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bb7c8dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_temp\n",
      "Accuracy: 0.26266666666666666\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.26      0.27       150\n",
      "           1       0.25      0.25      0.25       150\n",
      "           2       0.27      0.27      0.27       150\n",
      "           3       0.26      0.27      0.27       150\n",
      "           4       0.26      0.27      0.26       150\n",
      "\n",
      "   micro avg       0.26      0.26      0.26       750\n",
      "   macro avg       0.26      0.26      0.26       750\n",
      "weighted avg       0.26      0.26      0.26       750\n",
      " samples avg       0.26      0.26      0.26       750\n",
      "\n",
      "x_train_stat\n",
      "Accuracy: 0.23866666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.25      0.24       150\n",
      "           1       0.20      0.19      0.20       150\n",
      "           2       0.26      0.27      0.26       150\n",
      "           3       0.23      0.22      0.22       150\n",
      "           4       0.26      0.27      0.27       150\n",
      "\n",
      "   micro avg       0.24      0.24      0.24       750\n",
      "   macro avg       0.24      0.24      0.24       750\n",
      "weighted avg       0.24      0.24      0.24       750\n",
      " samples avg       0.24      0.24      0.24       750\n",
      "\n",
      "x_train_spect\n",
      "Accuracy: 0.188\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.01      0.03       150\n",
      "           1       0.19      0.41      0.26       150\n",
      "           2       0.12      0.03      0.04       150\n",
      "           3       0.14      0.01      0.01       150\n",
      "           4       0.19      0.48      0.27       150\n",
      "\n",
      "   micro avg       0.19      0.19      0.19       750\n",
      "   macro avg       0.18      0.19      0.12       750\n",
      "weighted avg       0.18      0.19      0.12       750\n",
      " samples avg       0.19      0.19      0.19       750\n",
      "\n",
      "x_train_stat_temp\n",
      "Accuracy: 0.24133333333333334\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.26      0.25       150\n",
      "           1       0.20      0.19      0.20       150\n",
      "           2       0.25      0.27      0.26       150\n",
      "           3       0.23      0.22      0.22       150\n",
      "           4       0.27      0.27      0.27       150\n",
      "\n",
      "   micro avg       0.24      0.24      0.24       750\n",
      "   macro avg       0.24      0.24      0.24       750\n",
      "weighted avg       0.24      0.24      0.24       750\n",
      " samples avg       0.24      0.24      0.24       750\n",
      "\n",
      "x_train_stat_spect\n",
      "Accuracy: 0.188\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.01      0.03       150\n",
      "           1       0.19      0.41      0.26       150\n",
      "           2       0.12      0.03      0.04       150\n",
      "           3       0.14      0.01      0.01       150\n",
      "           4       0.19      0.48      0.27       150\n",
      "\n",
      "   micro avg       0.19      0.19      0.19       750\n",
      "   macro avg       0.18      0.19      0.12       750\n",
      "weighted avg       0.18      0.19      0.12       750\n",
      " samples avg       0.19      0.19      0.19       750\n",
      "\n",
      "x_train_temp_spect\n",
      "Accuracy: 0.188\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.01      0.03       150\n",
      "           1       0.19      0.41      0.26       150\n",
      "           2       0.12      0.03      0.04       150\n",
      "           3       0.14      0.01      0.01       150\n",
      "           4       0.19      0.48      0.27       150\n",
      "\n",
      "   micro avg       0.19      0.19      0.19       750\n",
      "   macro avg       0.18      0.19      0.12       750\n",
      "weighted avg       0.18      0.19      0.12       750\n",
      " samples avg       0.19      0.19      0.19       750\n",
      "\n",
      "x_train_all_features\n",
      "Accuracy: 0.188\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.01      0.03       150\n",
      "           1       0.19      0.41      0.26       150\n",
      "           2       0.12      0.03      0.04       150\n",
      "           3       0.14      0.01      0.01       150\n",
      "           4       0.19      0.48      0.27       150\n",
      "\n",
      "   micro avg       0.19      0.19      0.19       750\n",
      "   macro avg       0.18      0.19      0.12       750\n",
      "weighted avg       0.18      0.19      0.12       750\n",
      " samples avg       0.19      0.19      0.19       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 14, 2):\n",
    "    print(ttt[i])\n",
    "    knnclf(t[i], y_train, t[i+1], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a201ff",
   "metadata": {},
   "source": [
    "# Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "85d5f8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statical features extraction start\n",
      "Trail  0\n",
      "Trail  1000\n",
      "Trail  2000\n",
      "Trail  3000\n",
      "Trail  4000\n",
      "Trail  0\n",
      "statical features extraction complete\n",
      "temporal features extraction start\n",
      "Trail  0\n",
      "Trail  1000\n",
      "Trail  2000\n",
      "Trail  3000\n",
      "Trail  4000\n",
      "Trail  0\n",
      "temporal features extraction end\n",
      "spectral features extraction start\n",
      "Trail  0\n",
      "Trail  1000\n",
      "Trail  2000\n",
      "Trail  3000\n",
      "Trail  4000\n",
      "Trail  0\n",
      "spectral features extraction end\n"
     ]
    }
   ],
   "source": [
    "x_train_temp, x_test_temp, x_train_stat, x_test_stat, x_train_spect, x_test_spect = check_rythm(\"theta\", x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "80377da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_arr(testlist):\n",
    "    output = list()\n",
    "    for i in testlist:\n",
    "        if isinstance(i, float)==False and isinstance(i, int)==False:\n",
    "            output.extend(i)\n",
    "        else:\n",
    "            output.append(i)\n",
    "    return output\n",
    "x_train_spect = np.array([flatten_arr(feat) for feat in x_train_spect])\n",
    "x_test_spect = np.array([flatten_arr(feat) for feat in x_test_spect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ea246eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_stat_temp = np.hstack((x_train_stat, x_train_temp))\n",
    "x_test_stat_temp = np.hstack((x_test_stat, x_test_temp))\n",
    "x_train_stat_spect = np.hstack((x_train_stat, x_train_spect))\n",
    "x_test_stat_spect = np.hstack((x_test_stat, x_test_spect))\n",
    "x_train_temp_spect = np.hstack((x_train_temp, x_train_spect))\n",
    "x_test_temp_spect = np.hstack((x_test_temp, x_test_spect))\n",
    "x_train_all_features = np.hstack((x_train_stat, x_train_temp, x_train_spect))\n",
    "x_test_all_features = np.hstack((x_test_stat, x_test_temp, x_test_spect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "25b865e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = [\"x_train_temp\", \"x_test_temp\", \"x_train_stat\", \"x_test_stat\", \"x_train_spect\", \"x_test_spect\",\n",
    "       \"x_train_stat_temp\", \"x_test_stat_temp\", \"x_train_stat_spect\", \"x_test_stat_spect\", \"x_train_temp_spect\",\n",
    "       \"x_test_temp_spect\", \"x_train_all_features\", \"x_test_all_features\"]\n",
    "t = [x_train_temp, x_test_temp, x_train_stat, x_test_stat, x_train_spect, x_test_spect,x_train_stat_temp, \n",
    "     x_test_stat_temp, x_train_stat_spect, x_test_stat_spect, x_train_temp_spect,x_test_temp_spect, \n",
    "     x_train_all_features, x_test_all_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0455d38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_temp\n",
      "Accuracy: 0.30666666666666664\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.31      0.31       150\n",
      "           1       0.35      0.30      0.32       150\n",
      "           2       0.30      0.32      0.31       150\n",
      "           3       0.28      0.29      0.28       150\n",
      "           4       0.30      0.32      0.31       150\n",
      "\n",
      "   micro avg       0.31      0.31      0.31       750\n",
      "   macro avg       0.31      0.31      0.31       750\n",
      "weighted avg       0.31      0.31      0.31       750\n",
      " samples avg       0.31      0.31      0.31       750\n",
      "\n",
      "x_train_stat\n",
      "Accuracy: 0.32266666666666666\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.30      0.31       150\n",
      "           1       0.35      0.35      0.35       150\n",
      "           2       0.34      0.33      0.33       150\n",
      "           3       0.32      0.31      0.32       150\n",
      "           4       0.29      0.32      0.31       150\n",
      "\n",
      "   micro avg       0.32      0.32      0.32       750\n",
      "   macro avg       0.32      0.32      0.32       750\n",
      "weighted avg       0.32      0.32      0.32       750\n",
      " samples avg       0.32      0.32      0.32       750\n",
      "\n",
      "x_train_spect\n",
      "Accuracy: 0.3506666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.33      0.34       150\n",
      "           1       0.33      0.34      0.33       150\n",
      "           2       0.36      0.34      0.35       150\n",
      "           3       0.36      0.35      0.36       150\n",
      "           4       0.36      0.39      0.37       150\n",
      "\n",
      "   micro avg       0.35      0.35      0.35       750\n",
      "   macro avg       0.35      0.35      0.35       750\n",
      "weighted avg       0.35      0.35      0.35       750\n",
      " samples avg       0.35      0.35      0.35       750\n",
      "\n",
      "x_train_stat_temp\n",
      "Accuracy: 0.32666666666666666\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.31      0.32       150\n",
      "           1       0.35      0.33      0.34       150\n",
      "           2       0.34      0.36      0.35       150\n",
      "           3       0.33      0.32      0.33       150\n",
      "           4       0.29      0.31      0.30       150\n",
      "\n",
      "   micro avg       0.33      0.33      0.33       750\n",
      "   macro avg       0.33      0.33      0.33       750\n",
      "weighted avg       0.33      0.33      0.33       750\n",
      " samples avg       0.33      0.33      0.33       750\n",
      "\n",
      "x_train_stat_spect\n",
      "Accuracy: 0.3506666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.33      0.34       150\n",
      "           1       0.33      0.34      0.33       150\n",
      "           2       0.36      0.34      0.35       150\n",
      "           3       0.36      0.35      0.36       150\n",
      "           4       0.36      0.39      0.37       150\n",
      "\n",
      "   micro avg       0.35      0.35      0.35       750\n",
      "   macro avg       0.35      0.35      0.35       750\n",
      "weighted avg       0.35      0.35      0.35       750\n",
      " samples avg       0.35      0.35      0.35       750\n",
      "\n",
      "x_train_temp_spect\n",
      "Accuracy: 0.3506666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.33      0.34       150\n",
      "           1       0.33      0.34      0.33       150\n",
      "           2       0.36      0.34      0.35       150\n",
      "           3       0.36      0.35      0.36       150\n",
      "           4       0.36      0.39      0.37       150\n",
      "\n",
      "   micro avg       0.35      0.35      0.35       750\n",
      "   macro avg       0.35      0.35      0.35       750\n",
      "weighted avg       0.35      0.35      0.35       750\n",
      " samples avg       0.35      0.35      0.35       750\n",
      "\n",
      "x_train_all_features\n",
      "Accuracy: 0.3506666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.33      0.34       150\n",
      "           1       0.33      0.34      0.33       150\n",
      "           2       0.36      0.34      0.35       150\n",
      "           3       0.36      0.35      0.36       150\n",
      "           4       0.36      0.39      0.37       150\n",
      "\n",
      "   micro avg       0.35      0.35      0.35       750\n",
      "   macro avg       0.35      0.35      0.35       750\n",
      "weighted avg       0.35      0.35      0.35       750\n",
      " samples avg       0.35      0.35      0.35       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 14, 2):\n",
    "    print(ttt[i])\n",
    "    knnclf(t[i], y_train, t[i+1], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ee4e77",
   "metadata": {},
   "source": [
    "# Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f736235e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statical features extraction start\n",
      "Trail  0\n",
      "Trail  1000\n",
      "Trail  2000\n",
      "Trail  3000\n",
      "Trail  4000\n",
      "Trail  0\n",
      "statical features extraction complete\n",
      "temporal features extraction start\n",
      "Trail  0\n",
      "Trail  1000\n",
      "Trail  2000\n",
      "Trail  3000\n",
      "Trail  4000\n",
      "Trail  0\n",
      "temporal features extraction end\n",
      "spectral features extraction start\n",
      "Trail  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97450\\OneDrive - Hamad bin Khalifa University\\Desktop\\Project\\Master_thesis_project\\OSF dataset\\Speech Decoding From EEG signals\\utils.py:135: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trail  1000\n",
      "Trail  2000\n",
      "Trail  3000\n",
      "Trail  4000\n",
      "Trail  0\n",
      "spectral features extraction end\n"
     ]
    }
   ],
   "source": [
    "x_train_temp, x_test_temp, x_train_stat, x_test_stat, x_train_spect, x_test_spect = check_rythm(\"alpha\", x_train, y_train, x_test, y_test)\n",
    "def flatten_arr(testlist):\n",
    "    output = list()\n",
    "    for i in testlist:\n",
    "        if isinstance(i, float)==False and isinstance(i, int)==False:\n",
    "            output.extend(i)\n",
    "        else:\n",
    "            output.append(i)\n",
    "    return output\n",
    "x_train_spect = np.array([flatten_arr(feat) for feat in x_train_spect])\n",
    "x_test_spect = np.array([flatten_arr(feat) for feat in x_test_spect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ff688b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_temp\n",
      "Accuracy: 0.24666666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.20      0.21       150\n",
      "           1       0.28      0.23      0.25       150\n",
      "           2       0.26      0.29      0.28       150\n",
      "           3       0.26      0.28      0.27       150\n",
      "           4       0.22      0.23      0.22       150\n",
      "\n",
      "   micro avg       0.25      0.25      0.25       750\n",
      "   macro avg       0.25      0.25      0.25       750\n",
      "weighted avg       0.25      0.25      0.25       750\n",
      " samples avg       0.25      0.25      0.25       750\n",
      "\n",
      "x_train_stat\n",
      "Accuracy: 0.268\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.25      0.26       150\n",
      "           1       0.23      0.20      0.22       150\n",
      "           2       0.28      0.29      0.28       150\n",
      "           3       0.29      0.32      0.31       150\n",
      "           4       0.26      0.29      0.27       150\n",
      "\n",
      "   micro avg       0.27      0.27      0.27       750\n",
      "   macro avg       0.27      0.27      0.27       750\n",
      "weighted avg       0.27      0.27      0.27       750\n",
      " samples avg       0.27      0.27      0.27       750\n",
      "\n",
      "x_train_spect\n",
      "Accuracy: 0.27066666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.24      0.24       150\n",
      "           1       0.26      0.23      0.25       150\n",
      "           2       0.26      0.25      0.26       150\n",
      "           3       0.28      0.33      0.30       150\n",
      "           4       0.30      0.30      0.30       150\n",
      "\n",
      "   micro avg       0.27      0.27      0.27       750\n",
      "   macro avg       0.27      0.27      0.27       750\n",
      "weighted avg       0.27      0.27      0.27       750\n",
      " samples avg       0.27      0.27      0.27       750\n",
      "\n",
      "x_train_stat_temp\n",
      "Accuracy: 0.24133333333333334\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.21      0.21       150\n",
      "           1       0.26      0.21      0.23       150\n",
      "           2       0.25      0.29      0.27       150\n",
      "           3       0.25      0.27      0.26       150\n",
      "           4       0.22      0.24      0.23       150\n",
      "\n",
      "   micro avg       0.24      0.24      0.24       750\n",
      "   macro avg       0.24      0.24      0.24       750\n",
      "weighted avg       0.24      0.24      0.24       750\n",
      " samples avg       0.24      0.24      0.24       750\n",
      "\n",
      "x_train_stat_spect\n",
      "Accuracy: 0.27066666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.24      0.24       150\n",
      "           1       0.26      0.23      0.25       150\n",
      "           2       0.26      0.25      0.26       150\n",
      "           3       0.28      0.33      0.30       150\n",
      "           4       0.30      0.30      0.30       150\n",
      "\n",
      "   micro avg       0.27      0.27      0.27       750\n",
      "   macro avg       0.27      0.27      0.27       750\n",
      "weighted avg       0.27      0.27      0.27       750\n",
      " samples avg       0.27      0.27      0.27       750\n",
      "\n",
      "x_train_temp_spect\n",
      "Accuracy: 0.27066666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.24      0.24       150\n",
      "           1       0.26      0.23      0.25       150\n",
      "           2       0.26      0.25      0.26       150\n",
      "           3       0.28      0.33      0.30       150\n",
      "           4       0.30      0.30      0.30       150\n",
      "\n",
      "   micro avg       0.27      0.27      0.27       750\n",
      "   macro avg       0.27      0.27      0.27       750\n",
      "weighted avg       0.27      0.27      0.27       750\n",
      " samples avg       0.27      0.27      0.27       750\n",
      "\n",
      "x_train_all_features\n",
      "Accuracy: 0.27066666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.24      0.24       150\n",
      "           1       0.26      0.23      0.25       150\n",
      "           2       0.26      0.25      0.26       150\n",
      "           3       0.28      0.33      0.30       150\n",
      "           4       0.30      0.30      0.30       150\n",
      "\n",
      "   micro avg       0.27      0.27      0.27       750\n",
      "   macro avg       0.27      0.27      0.27       750\n",
      "weighted avg       0.27      0.27      0.27       750\n",
      " samples avg       0.27      0.27      0.27       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_stat_temp = np.hstack((x_train_stat, x_train_temp))\n",
    "x_test_stat_temp = np.hstack((x_test_stat, x_test_temp))\n",
    "x_train_stat_spect = np.hstack((x_train_stat, x_train_spect))\n",
    "x_test_stat_spect = np.hstack((x_test_stat, x_test_spect))\n",
    "x_train_temp_spect = np.hstack((x_train_temp, x_train_spect))\n",
    "x_test_temp_spect = np.hstack((x_test_temp, x_test_spect))\n",
    "x_train_all_features = np.hstack((x_train_stat, x_train_temp, x_train_spect))\n",
    "x_test_all_features = np.hstack((x_test_stat, x_test_temp, x_test_spect))\n",
    "ttt = [\"x_train_temp\", \"x_test_temp\", \"x_train_stat\", \"x_test_stat\", \"x_train_spect\", \"x_test_spect\",\n",
    "       \"x_train_stat_temp\", \"x_test_stat_temp\", \"x_train_stat_spect\", \"x_test_stat_spect\", \"x_train_temp_spect\",\n",
    "       \"x_test_temp_spect\", \"x_train_all_features\", \"x_test_all_features\"]\n",
    "t = [x_train_temp, x_test_temp, x_train_stat, x_test_stat, x_train_spect, x_test_spect,x_train_stat_temp, \n",
    "     x_test_stat_temp, x_train_stat_spect, x_test_stat_spect, x_train_temp_spect,x_test_temp_spect, \n",
    "     x_train_all_features, x_test_all_features]\n",
    "for i in range(0, 14, 2):\n",
    "    print(ttt[i])\n",
    "    knnclf(t[i], y_train, t[i+1], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136e128e",
   "metadata": {},
   "source": [
    "# Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4b81381c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statical features extraction start\n",
      "Trail  0\n",
      "Trail  1000\n",
      "Trail  2000\n",
      "Trail  3000\n",
      "Trail  4000\n",
      "Trail  0\n",
      "statical features extraction complete\n",
      "temporal features extraction start\n",
      "Trail  0\n",
      "Trail  1000\n",
      "Trail  2000\n",
      "Trail  3000\n",
      "Trail  4000\n",
      "Trail  0\n",
      "temporal features extraction end\n",
      "spectral features extraction start\n",
      "Trail  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97450\\OneDrive - Hamad bin Khalifa University\\Desktop\\Project\\Master_thesis_project\\OSF dataset\\Speech Decoding From EEG signals\\utils.py:135: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trail  1000\n",
      "Trail  2000\n",
      "Trail  3000\n",
      "Trail  4000\n",
      "Trail  0\n",
      "spectral features extraction end\n"
     ]
    }
   ],
   "source": [
    "x_train_temp, x_test_temp, x_train_stat, x_test_stat, x_train_spect, x_test_spect = check_rythm(\"beta\", x_train, y_train, x_test, y_test)\n",
    "def flatten_arr(testlist):\n",
    "    output = list()\n",
    "    for i in testlist:\n",
    "        if isinstance(i, float)==False and isinstance(i, int)==False:\n",
    "            output.extend(i)\n",
    "        else:\n",
    "            output.append(i)\n",
    "    return output\n",
    "x_train_spect = np.array([flatten_arr(feat) for feat in x_train_spect])\n",
    "x_test_spect = np.array([flatten_arr(feat) for feat in x_test_spect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0be4b6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_temp\n",
      "Accuracy: 0.3933333333333333\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.35      0.35       150\n",
      "           1       0.39      0.39      0.39       150\n",
      "           2       0.41      0.40      0.40       150\n",
      "           3       0.39      0.36      0.37       150\n",
      "           4       0.43      0.46      0.45       150\n",
      "\n",
      "   micro avg       0.39      0.39      0.39       750\n",
      "   macro avg       0.39      0.39      0.39       750\n",
      "weighted avg       0.39      0.39      0.39       750\n",
      " samples avg       0.39      0.39      0.39       750\n",
      "\n",
      "x_train_stat\n",
      "Accuracy: 0.384\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.39      0.40       150\n",
      "           1       0.37      0.35      0.36       150\n",
      "           2       0.40      0.41      0.41       150\n",
      "           3       0.38      0.39      0.39       150\n",
      "           4       0.36      0.37      0.37       150\n",
      "\n",
      "   micro avg       0.38      0.38      0.38       750\n",
      "   macro avg       0.38      0.38      0.38       750\n",
      "weighted avg       0.38      0.38      0.38       750\n",
      " samples avg       0.38      0.38      0.38       750\n",
      "\n",
      "x_train_spect\n",
      "Accuracy: 0.37066666666666664\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.33      0.34       150\n",
      "           1       0.33      0.35      0.34       150\n",
      "           2       0.39      0.37      0.38       150\n",
      "           3       0.37      0.38      0.37       150\n",
      "           4       0.41      0.41      0.41       150\n",
      "\n",
      "   micro avg       0.37      0.37      0.37       750\n",
      "   macro avg       0.37      0.37      0.37       750\n",
      "weighted avg       0.37      0.37      0.37       750\n",
      " samples avg       0.37      0.37      0.37       750\n",
      "\n",
      "x_train_stat_temp\n",
      "Accuracy: 0.39066666666666666\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.35      0.35       150\n",
      "           1       0.38      0.39      0.39       150\n",
      "           2       0.40      0.40      0.40       150\n",
      "           3       0.39      0.36      0.37       150\n",
      "           4       0.43      0.46      0.45       150\n",
      "\n",
      "   micro avg       0.39      0.39      0.39       750\n",
      "   macro avg       0.39      0.39      0.39       750\n",
      "weighted avg       0.39      0.39      0.39       750\n",
      " samples avg       0.39      0.39      0.39       750\n",
      "\n",
      "x_train_stat_spect\n",
      "Accuracy: 0.37066666666666664\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.33      0.34       150\n",
      "           1       0.33      0.35      0.34       150\n",
      "           2       0.39      0.37      0.38       150\n",
      "           3       0.37      0.38      0.37       150\n",
      "           4       0.41      0.41      0.41       150\n",
      "\n",
      "   micro avg       0.37      0.37      0.37       750\n",
      "   macro avg       0.37      0.37      0.37       750\n",
      "weighted avg       0.37      0.37      0.37       750\n",
      " samples avg       0.37      0.37      0.37       750\n",
      "\n",
      "x_train_temp_spect\n",
      "Accuracy: 0.37066666666666664\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.33      0.34       150\n",
      "           1       0.33      0.35      0.34       150\n",
      "           2       0.39      0.37      0.38       150\n",
      "           3       0.37      0.38      0.37       150\n",
      "           4       0.41      0.41      0.41       150\n",
      "\n",
      "   micro avg       0.37      0.37      0.37       750\n",
      "   macro avg       0.37      0.37      0.37       750\n",
      "weighted avg       0.37      0.37      0.37       750\n",
      " samples avg       0.37      0.37      0.37       750\n",
      "\n",
      "x_train_all_features\n",
      "Accuracy: 0.37066666666666664\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.33      0.34       150\n",
      "           1       0.33      0.35      0.34       150\n",
      "           2       0.39      0.37      0.38       150\n",
      "           3       0.37      0.38      0.37       150\n",
      "           4       0.41      0.41      0.41       150\n",
      "\n",
      "   micro avg       0.37      0.37      0.37       750\n",
      "   macro avg       0.37      0.37      0.37       750\n",
      "weighted avg       0.37      0.37      0.37       750\n",
      " samples avg       0.37      0.37      0.37       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_stat_temp = np.hstack((x_train_stat, x_train_temp))\n",
    "x_test_stat_temp = np.hstack((x_test_stat, x_test_temp))\n",
    "x_train_stat_spect = np.hstack((x_train_stat, x_train_spect))\n",
    "x_test_stat_spect = np.hstack((x_test_stat, x_test_spect))\n",
    "x_train_temp_spect = np.hstack((x_train_temp, x_train_spect))\n",
    "x_test_temp_spect = np.hstack((x_test_temp, x_test_spect))\n",
    "x_train_all_features = np.hstack((x_train_stat, x_train_temp, x_train_spect))\n",
    "x_test_all_features = np.hstack((x_test_stat, x_test_temp, x_test_spect))\n",
    "ttt = [\"x_train_temp\", \"x_test_temp\", \"x_train_stat\", \"x_test_stat\", \"x_train_spect\", \"x_test_spect\",\n",
    "       \"x_train_stat_temp\", \"x_test_stat_temp\", \"x_train_stat_spect\", \"x_test_stat_spect\", \"x_train_temp_spect\",\n",
    "       \"x_test_temp_spect\", \"x_train_all_features\", \"x_test_all_features\"]\n",
    "t = [x_train_temp, x_test_temp, x_train_stat, x_test_stat, x_train_spect, x_test_spect,x_train_stat_temp, \n",
    "     x_test_stat_temp, x_train_stat_spect, x_test_stat_spect, x_train_temp_spect,x_test_temp_spect, \n",
    "     x_train_all_features, x_test_all_features]\n",
    "for i in range(0, 14, 2):\n",
    "    print(ttt[i])\n",
    "    knnclf(t[i], y_train, t[i+1], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f6e3d4",
   "metadata": {},
   "source": [
    "# Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4f1d4d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statical features extraction start\n",
      "Trail  0\n",
      "Trail  1000\n",
      "Trail  2000\n",
      "Trail  3000\n",
      "Trail  4000\n",
      "Trail  0\n",
      "statical features extraction complete\n",
      "temporal features extraction start\n",
      "Trail  0\n",
      "Trail  1000\n",
      "Trail  2000\n",
      "Trail  3000\n",
      "Trail  4000\n",
      "Trail  0\n",
      "temporal features extraction end\n",
      "spectral features extraction start\n",
      "Trail  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97450\\OneDrive - Hamad bin Khalifa University\\Desktop\\Project\\Master_thesis_project\\OSF dataset\\Speech Decoding From EEG signals\\utils.py:135: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trail  1000\n",
      "Trail  2000\n",
      "Trail  3000\n",
      "Trail  4000\n",
      "Trail  0\n",
      "spectral features extraction end\n"
     ]
    }
   ],
   "source": [
    "x_train_temp, x_test_temp, x_train_stat, x_test_stat, x_train_spect, x_test_spect = check_rythm(\"gamma\", x_train, y_train, x_test, y_test)\n",
    "def flatten_arr(testlist):\n",
    "    output = list()\n",
    "    for i in testlist:\n",
    "        if isinstance(i, float)==False and isinstance(i, int)==False:\n",
    "            output.extend(i)\n",
    "        else:\n",
    "            output.append(i)\n",
    "    return output\n",
    "x_train_spect = np.array([flatten_arr(feat) for feat in x_train_spect])\n",
    "x_test_spect = np.array([flatten_arr(feat) for feat in x_test_spect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3cb94ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_temp\n",
      "Accuracy: 0.712\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.67      0.67       150\n",
      "           1       0.66      0.69      0.68       150\n",
      "           2       0.77      0.72      0.74       150\n",
      "           3       0.70      0.77      0.73       150\n",
      "           4       0.76      0.71      0.74       150\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       750\n",
      "   macro avg       0.71      0.71      0.71       750\n",
      "weighted avg       0.71      0.71      0.71       750\n",
      " samples avg       0.71      0.71      0.71       750\n",
      "\n",
      "x_train_stat\n",
      "Accuracy: 0.5533333333333333\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.58      0.56       150\n",
      "           1       0.50      0.53      0.51       150\n",
      "           2       0.59      0.52      0.55       150\n",
      "           3       0.52      0.52      0.52       150\n",
      "           4       0.62      0.62      0.62       150\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       750\n",
      "   macro avg       0.55      0.55      0.55       750\n",
      "weighted avg       0.55      0.55      0.55       750\n",
      " samples avg       0.55      0.55      0.55       750\n",
      "\n",
      "x_train_spect\n",
      "Accuracy: 0.4266666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.47      0.46       150\n",
      "           1       0.39      0.42      0.41       150\n",
      "           2       0.43      0.42      0.42       150\n",
      "           3       0.41      0.39      0.40       150\n",
      "           4       0.45      0.43      0.44       150\n",
      "\n",
      "   micro avg       0.43      0.43      0.43       750\n",
      "   macro avg       0.43      0.43      0.43       750\n",
      "weighted avg       0.43      0.43      0.43       750\n",
      " samples avg       0.43      0.43      0.43       750\n",
      "\n",
      "x_train_stat_temp\n",
      "Accuracy: 0.7146666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       150\n",
      "           1       0.66      0.69      0.68       150\n",
      "           2       0.77      0.72      0.74       150\n",
      "           3       0.71      0.77      0.73       150\n",
      "           4       0.76      0.71      0.74       150\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       750\n",
      "   macro avg       0.72      0.71      0.72       750\n",
      "weighted avg       0.72      0.71      0.72       750\n",
      " samples avg       0.71      0.71      0.71       750\n",
      "\n",
      "x_train_stat_spect\n",
      "Accuracy: 0.4266666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.47      0.46       150\n",
      "           1       0.39      0.42      0.41       150\n",
      "           2       0.43      0.42      0.42       150\n",
      "           3       0.41      0.39      0.40       150\n",
      "           4       0.45      0.43      0.44       150\n",
      "\n",
      "   micro avg       0.43      0.43      0.43       750\n",
      "   macro avg       0.43      0.43      0.43       750\n",
      "weighted avg       0.43      0.43      0.43       750\n",
      " samples avg       0.43      0.43      0.43       750\n",
      "\n",
      "x_train_temp_spect\n",
      "Accuracy: 0.4266666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.47      0.46       150\n",
      "           1       0.39      0.42      0.41       150\n",
      "           2       0.43      0.42      0.42       150\n",
      "           3       0.41      0.39      0.40       150\n",
      "           4       0.45      0.43      0.44       150\n",
      "\n",
      "   micro avg       0.43      0.43      0.43       750\n",
      "   macro avg       0.43      0.43      0.43       750\n",
      "weighted avg       0.43      0.43      0.43       750\n",
      " samples avg       0.43      0.43      0.43       750\n",
      "\n",
      "x_train_all_features\n",
      "Accuracy: 0.4266666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.47      0.46       150\n",
      "           1       0.39      0.42      0.41       150\n",
      "           2       0.43      0.42      0.42       150\n",
      "           3       0.41      0.39      0.40       150\n",
      "           4       0.45      0.43      0.44       150\n",
      "\n",
      "   micro avg       0.43      0.43      0.43       750\n",
      "   macro avg       0.43      0.43      0.43       750\n",
      "weighted avg       0.43      0.43      0.43       750\n",
      " samples avg       0.43      0.43      0.43       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_stat_temp = np.hstack((x_train_stat, x_train_temp))\n",
    "x_test_stat_temp = np.hstack((x_test_stat, x_test_temp))\n",
    "x_train_stat_spect = np.hstack((x_train_stat, x_train_spect))\n",
    "x_test_stat_spect = np.hstack((x_test_stat, x_test_spect))\n",
    "x_train_temp_spect = np.hstack((x_train_temp, x_train_spect))\n",
    "x_test_temp_spect = np.hstack((x_test_temp, x_test_spect))\n",
    "x_train_all_features = np.hstack((x_train_stat, x_train_temp, x_train_spect))\n",
    "x_test_all_features = np.hstack((x_test_stat, x_test_temp, x_test_spect))\n",
    "ttt = [\"x_train_temp\", \"x_test_temp\", \"x_train_stat\", \"x_test_stat\", \"x_train_spect\", \"x_test_spect\",\n",
    "       \"x_train_stat_temp\", \"x_test_stat_temp\", \"x_train_stat_spect\", \"x_test_stat_spect\", \"x_train_temp_spect\",\n",
    "       \"x_test_temp_spect\", \"x_train_all_features\", \"x_test_all_features\"]\n",
    "t = [x_train_temp, x_test_temp, x_train_stat, x_test_stat, x_train_spect, x_test_spect,x_train_stat_temp, \n",
    "     x_test_stat_temp, x_train_stat_spect, x_test_stat_spect, x_train_temp_spect,x_test_temp_spect, \n",
    "     x_train_all_features, x_test_all_features]\n",
    "for i in range(0, 14, 2):\n",
    "    print(ttt[i])\n",
    "    knnclf(t[i], y_train, t[i+1], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7a52a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statical features extraction start\n",
      "Trail  0\n",
      "Trail  1000\n",
      "Trail  2000\n",
      "Trail  3000\n",
      "Trail  4000\n",
      "Trail  0\n",
      "statical features extraction complete\n",
      "temporal features extraction start\n",
      "Trail  0\n",
      "Trail  1000\n",
      "Trail  2000\n",
      "Trail  3000\n",
      "Trail  4000\n",
      "Trail  0\n",
      "temporal features extraction end\n",
      "spectral features extraction start\n",
      "Trail  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97450\\OneDrive - Hamad bin Khalifa University\\Desktop\\Project\\Master_thesis_project\\OSF dataset\\Speech Decoding From EEG signals\\utils.py:135: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trail  1000\n",
      "Trail  2000\n",
      "Trail  3000\n",
      "Trail  4000\n",
      "Trail  0\n",
      "spectral features extraction end\n"
     ]
    }
   ],
   "source": [
    "x_train_temp, x_test_temp, x_train_stat, x_test_stat, x_train_spect, x_test_spect = check_rythm(\"gamma\", x_train, y_train, x_test, y_test)\n",
    "def flatten_arr(testlist):\n",
    "    output = list()\n",
    "    for i in testlist:\n",
    "        if isinstance(i, float)==False and isinstance(i, int)==False:\n",
    "            output.extend(i)\n",
    "        else:\n",
    "            output.append(i)\n",
    "    return output\n",
    "x_train_spect = np.array([flatten_arr(feat) for feat in x_train_spect])\n",
    "x_test_spect = np.array([flatten_arr(feat) for feat in x_test_spect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0f1a4781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8f689a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_train, y_train, x_test, y_test):\n",
    "    kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "    kclf.fit(x_train, y_train)\n",
    "    y_pred = kclf.predict(x_test)\n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1183ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_selection(train, ytrain, test, ytest):\n",
    "    channel = []\n",
    "    acccc = []\n",
    "    tempfeatures, vtemp = train, test\n",
    "    total_feature = train.shape[1]\n",
    "    feature_per_channel = total_feature//64\n",
    "    for i in range(0, total_feature, feature_per_channel):\n",
    "        acc = model(tempfeatures[:,i:i+feature_per_channel], ytrain, vtemp[:,i:i+feature_per_channel], ytest)\n",
    "        if i!=0:\n",
    "            channel.append(i//feature_per_channel)\n",
    "        else: \n",
    "            channel.append(i)\n",
    "        acccc.append(acc)\n",
    "    channel__ = [ch for ch, a in zip(channel, acccc) if a>=np.mean(acccc)]\n",
    "    ch_names = [channels_names[i] for i in channel__]\n",
    "    print(f\"Top channel : {len(channel__)} \\n {ch_names}\")\n",
    "    \n",
    "#     tempfeatures, vtemp = train, test\n",
    "    temp, vtem = [], []\n",
    "    for ch1 in tempfeatures:\n",
    "        newtemp = []\n",
    "        for i in range(0, total_feature, feature_per_channel):\n",
    "            if i!=0:\n",
    "                if i//feature_per_channel in channel__:\n",
    "                    newtemp.extend(ch1[i:i+feature_per_channel])\n",
    "        temp.append(newtemp)\n",
    "\n",
    "    for ch2 in vtemp:\n",
    "        newvtem = []\n",
    "        for i in range(0, total_feature, feature_per_channel):\n",
    "            if i!=0:\n",
    "                if i//feature_per_channel in channel__:\n",
    "                    newvtem.extend(ch2[i:i+feature_per_channel])\n",
    "        vtem.append(newvtem)\n",
    "    temp, vtem = np.asarray(temp), np.asarray(vtem)\n",
    "    knnclf(temp, ytrain, vtem, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5d3f78",
   "metadata": {},
   "source": [
    "# Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dbd7d7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 31 \n",
      " ['F7', 'F4', 'FC5', 'FC1', 'FC2', 'T7', 'C3', 'T8', 'TP9', 'CP1', 'CP2', 'P7', 'Pz', 'PO9', 'Oz', 'PO10', 'AF3', 'AF4', 'AF8', 'F1', 'F2', 'F6', 'FC3', 'FC4', 'C2', 'C6', 'CP3', 'CP4', 'TP8', 'PO7', 'PO4']\n",
      "Accuracy: 0.7186666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.70       150\n",
      "           1       0.70      0.70      0.70       150\n",
      "           2       0.78      0.79      0.78       150\n",
      "           3       0.70      0.73      0.71       150\n",
      "           4       0.71      0.68      0.70       150\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       750\n",
      "   macro avg       0.72      0.72      0.72       750\n",
      "weighted avg       0.72      0.72      0.72       750\n",
      " samples avg       0.72      0.72      0.72       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_selection(x_train_temp, y_train,  x_test_temp, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5974c9",
   "metadata": {},
   "source": [
    "# Statistical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4cde18c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 29 \n",
      " ['Fp1', 'Fp2', 'F3', 'F8', 'FC5', 'C4', 'T8', 'TP9', 'CP6', 'TP10', 'P7', 'P8', 'PO9', 'Oz', 'AF4', 'F1', 'F6', 'FT7', 'FC4', 'FT10', 'C5', 'C2', 'C6', 'TP7', 'CP4', 'TP8', 'P5', 'P6', 'PO8']\n",
      "Accuracy: 0.536\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.57      0.55       150\n",
      "           1       0.49      0.53      0.51       150\n",
      "           2       0.55      0.51      0.53       150\n",
      "           3       0.51      0.49      0.50       150\n",
      "           4       0.61      0.57      0.59       150\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       750\n",
      "   macro avg       0.54      0.54      0.54       750\n",
      "weighted avg       0.54      0.54      0.54       750\n",
      " samples avg       0.54      0.54      0.54       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_selection(x_train_stat, y_train,  x_test_stat, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540baa70",
   "metadata": {},
   "source": [
    "# Spectrals features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7e316fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 31 \n",
      " ['Fp2', 'F7', 'Fz', 'F4', 'FC6', 'T7', 'C4', 'T8', 'TP9', 'CP5', 'P7', 'P3', 'Pz', 'PO9', 'Oz', 'O2', 'PO10', 'AF7', 'F1', 'F2', 'F6', 'FT9', 'FC4', 'FT8', 'FT10', 'C5', 'C2', 'C6', 'P1', 'P2', 'PO7']\n",
      "Accuracy: 0.396\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.43      0.43       150\n",
      "           1       0.37      0.44      0.40       150\n",
      "           2       0.39      0.37      0.38       150\n",
      "           3       0.39      0.39      0.39       150\n",
      "           4       0.40      0.35      0.37       150\n",
      "\n",
      "   micro avg       0.40      0.40      0.40       750\n",
      "   macro avg       0.40      0.40      0.40       750\n",
      "weighted avg       0.40      0.40      0.40       750\n",
      " samples avg       0.40      0.40      0.40       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_selection(x_train_spect, y_train,  x_test_spect, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dbf7f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_stat_temp = np.hstack((x_train_stat, x_train_temp))\n",
    "x_test_stat_temp = np.hstack((x_test_stat, x_test_temp))\n",
    "x_train_stat_spect = np.hstack((x_train_stat, x_train_spect))\n",
    "x_test_stat_spect = np.hstack((x_test_stat, x_test_spect))\n",
    "x_train_temp_spect = np.hstack((x_train_temp, x_train_spect))\n",
    "x_test_temp_spect = np.hstack((x_test_temp, x_test_spect))\n",
    "x_train_all_features = np.hstack((x_train_stat, x_train_temp, x_train_spect))\n",
    "x_test_all_features = np.hstack((x_test_stat, x_test_temp, x_test_spect))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28354fca",
   "metadata": {},
   "source": [
    "# stat_temp features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c9c307be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 16 \n",
      " ['C2', 'C6', 'TP7', 'CP3', 'CPz', 'CP4', 'TP8', 'P5', 'P1', 'P2', 'P6', 'PO7', 'PO3', 'POz', 'PO4', 'PO8']\n",
      "Accuracy: 0.7186666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.69       150\n",
      "           1       0.66      0.71      0.68       150\n",
      "           2       0.79      0.73      0.76       150\n",
      "           3       0.71      0.78      0.74       150\n",
      "           4       0.75      0.70      0.72       150\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       750\n",
      "   macro avg       0.72      0.72      0.72       750\n",
      "weighted avg       0.72      0.72      0.72       750\n",
      " samples avg       0.72      0.72      0.72       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_selection(x_train_stat_temp, y_train,  x_test_stat_temp, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458e30d8",
   "metadata": {},
   "source": [
    "# stat_spect features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b4038a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 11 \n",
      " ['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC1', 'P8', 'AF4', 'TP7']\n",
      "Accuracy: 0.24\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.27      0.25       150\n",
      "           1       0.25      0.24      0.24       150\n",
      "           2       0.25      0.26      0.26       150\n",
      "           3       0.20      0.18      0.19       150\n",
      "           4       0.25      0.25      0.25       150\n",
      "\n",
      "   micro avg       0.24      0.24      0.24       750\n",
      "   macro avg       0.24      0.24      0.24       750\n",
      "weighted avg       0.24      0.24      0.24       750\n",
      " samples avg       0.24      0.24      0.24       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_selection(x_train_stat_spect, y_train,  x_test_stat_spect, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8474dbaa",
   "metadata": {},
   "source": [
    "# Temp_spect feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d958670e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 8 \n",
      " ['Fp1', 'Fp2', 'F3', 'CP5', 'P3', 'PO10', 'AF7', 'C6']\n",
      "Accuracy: 0.28\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.37      0.35       150\n",
      "           1       0.30      0.25      0.27       150\n",
      "           2       0.27      0.27      0.27       150\n",
      "           3       0.23      0.23      0.23       150\n",
      "           4       0.27      0.27      0.27       150\n",
      "\n",
      "   micro avg       0.28      0.28      0.28       750\n",
      "   macro avg       0.28      0.28      0.28       750\n",
      "weighted avg       0.28      0.28      0.28       750\n",
      " samples avg       0.28      0.28      0.28       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_selection(x_train_temp_spect, y_train,  x_test_temp_spect, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5656c4cb",
   "metadata": {},
   "source": [
    "# All spect, temp and stat feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8dde1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 10 \n",
      " ['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'AF8']\n",
      "Accuracy: 0.23466666666666666\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.23      0.23       150\n",
      "           1       0.31      0.30      0.31       150\n",
      "           2       0.21      0.19      0.20       150\n",
      "           3       0.20      0.23      0.21       150\n",
      "           4       0.23      0.23      0.23       150\n",
      "\n",
      "   micro avg       0.23      0.23      0.23       750\n",
      "   macro avg       0.24      0.23      0.23       750\n",
      "weighted avg       0.24      0.23      0.23       750\n",
      " samples avg       0.23      0.23      0.23       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_selection(x_train_all_features, y_train,  x_test_all_features, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "18ad7d34",
   "metadata": {},
   "outputs": [],
   "source": [
    " def forward(train, ytrain, test, ytest):\n",
    "    total_feature = train.shape[1]\n",
    "    feature_per_channel = total_feature//64\n",
    "    channel = [0]\n",
    "    tempfeatures, vtemp = train[:,0:feature_per_channel], test[:, 0:feature_per_channel]\n",
    "    for i in range(0, total_feature, feature_per_channel):\n",
    "        if i==0:\n",
    "            cuacc = model(tempfeatures, ytrain, vtemp, ytest)\n",
    "            preacc = cuacc\n",
    "        else:\n",
    "            temppp = [np.concatenate((tempf, fff), axis=None) for tempf, fff in zip(tempfeatures, train[:,i:i+feature_per_channel])]\n",
    "            vtemppp = [np.concatenate((tempf, fff), axis=None) for tempf, fff in zip(vtemp, test[:,i:i+feature_per_channel])]\n",
    "            cuacc = model(temppp, ytrain, vtemppp, ytest)\n",
    "#             print('current accuracy: '+str(cuacc))\n",
    "            if cuacc>preacc:\n",
    "                preacc = cuacc\n",
    "                tempfeatures = temppp\n",
    "                vtemp = vtemppp\n",
    "                channel.append(i//feature_per_channel)\n",
    "#                 print('previous accuracy: '+str(preacc))\n",
    "                #print('added '+str(channel_names[i//feature_per_channel]))\n",
    "    ch_names = [channels_names[i] for i in channel]\n",
    "    print(f\"Top channel : {len(channel)} \\n {ch_names}\")\n",
    "    knnclf(tempfeatures, ytrain, vtemp, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9f6b0f",
   "metadata": {},
   "source": [
    "# Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cb209101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 38 \n",
      " ['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', 'T7', 'C3', 'Cz', 'C4', 'T8', 'TP9', 'CP5', 'CP1', 'CP6', 'TP10', 'P7', 'PO9', 'O1', 'AF4', 'AF8', 'F1', 'FT9', 'FC4', 'FT8', 'FT10', 'C6', 'CP3', 'CPz', 'CP4', 'P6', 'PO7', 'PO3']\n",
      "Accuracy: 0.7386666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75       150\n",
      "           1       0.67      0.71      0.69       150\n",
      "           2       0.78      0.77      0.77       150\n",
      "           3       0.73      0.77      0.75       150\n",
      "           4       0.77      0.70      0.73       150\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       750\n",
      "   macro avg       0.74      0.74      0.74       750\n",
      "weighted avg       0.74      0.74      0.74       750\n",
      " samples avg       0.74      0.74      0.74       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forward(x_train_temp, y_train,  x_test_temp, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90e67b",
   "metadata": {},
   "source": [
    "# Statistical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fafd4a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 29 \n",
      " ['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'FC5', 'FC1', 'FC2', 'C3', 'C4', 'T8', 'TP9', 'CP2', 'CP6', 'P7', 'P3', 'Pz', 'Oz', 'PO10', 'AF3', 'AF4', 'F1', 'F2', 'FT7', 'FC3', 'FC4', 'C2', 'P5']\n",
      "Accuracy: 0.544\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.53      0.52       150\n",
      "           1       0.50      0.53      0.51       150\n",
      "           2       0.63      0.50      0.56       150\n",
      "           3       0.52      0.56      0.54       150\n",
      "           4       0.58      0.59      0.59       150\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       750\n",
      "   macro avg       0.55      0.54      0.54       750\n",
      "weighted avg       0.55      0.54      0.54       750\n",
      " samples avg       0.54      0.54      0.54       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forward(x_train_stat, y_train,  x_test_stat, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eee1e4",
   "metadata": {},
   "source": [
    "# Spectrals features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c2fd995c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 24 \n",
      " ['Fp1', 'Fp2', 'FC5', 'C3', 'Cz', 'TP9', 'Pz', 'O1', 'AF7', 'AF3', 'AF4', 'AF8', 'F5', 'F2', 'FT9', 'FT7', 'FC3', 'FT8', 'FT10', 'CP4', 'TP8', 'P5', 'P1', 'PO8']\n",
      "Accuracy: 0.39866666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.47      0.45       150\n",
      "           1       0.34      0.35      0.34       150\n",
      "           2       0.38      0.35      0.36       150\n",
      "           3       0.42      0.42      0.42       150\n",
      "           4       0.42      0.41      0.42       150\n",
      "\n",
      "   micro avg       0.40      0.40      0.40       750\n",
      "   macro avg       0.40      0.40      0.40       750\n",
      "weighted avg       0.40      0.40      0.40       750\n",
      " samples avg       0.40      0.40      0.40       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forward(x_train_spect, y_train,  x_test_spect, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93bd873",
   "metadata": {},
   "source": [
    "# stat_temp features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "65088f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 23 \n",
      " ['Fp1', 'Fp2', 'F7', 'F3', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'T7', 'C3', 'Cz', 'T8', 'TP9', 'CP1', 'CP6', 'P3', 'P4', 'FT7', 'FC3', 'FC4', 'FT8', 'FT10']\n",
      "Accuracy: 0.5653333333333334\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.61      0.58       150\n",
      "           1       0.54      0.51      0.52       150\n",
      "           2       0.63      0.56      0.59       150\n",
      "           3       0.51      0.55      0.53       150\n",
      "           4       0.61      0.60      0.60       150\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       750\n",
      "   macro avg       0.57      0.57      0.57       750\n",
      "weighted avg       0.57      0.57      0.57       750\n",
      " samples avg       0.57      0.57      0.57       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forward(x_train_stat_temp, y_train,  x_test_stat_temp, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0699b68c",
   "metadata": {},
   "source": [
    "# stat_spect features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "08f21e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 7 \n",
      " ['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8']\n",
      "Accuracy: 0.556\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.59      0.57       150\n",
      "           1       0.51      0.53      0.52       150\n",
      "           2       0.61      0.53      0.57       150\n",
      "           3       0.52      0.52      0.52       150\n",
      "           4       0.61      0.61      0.61       150\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       750\n",
      "   macro avg       0.56      0.56      0.56       750\n",
      "weighted avg       0.56      0.56      0.56       750\n",
      " samples avg       0.56      0.56      0.56       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forward(x_train_stat_spect, y_train,  x_test_stat_spect, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3ae72",
   "metadata": {},
   "source": [
    "# Temp_spect feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ad8bdd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 2 \n",
      " ['Fp1', 'Fp2']\n",
      "Accuracy: 0.7\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       150\n",
      "           1       0.66      0.70      0.68       150\n",
      "           2       0.76      0.72      0.74       150\n",
      "           3       0.69      0.73      0.71       150\n",
      "           4       0.72      0.67      0.69       150\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       750\n",
      "   macro avg       0.70      0.70      0.70       750\n",
      "weighted avg       0.70      0.70      0.70       750\n",
      " samples avg       0.70      0.70      0.70       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forward(x_train_temp_spect, y_train,  x_test_temp_spect, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dc2920",
   "metadata": {},
   "source": [
    "# All spect, temp and stat feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a56bd58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 9 \n",
      " ['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1']\n",
      "Accuracy: 0.7106666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       150\n",
      "           1       0.67      0.69      0.68       150\n",
      "           2       0.76      0.73      0.75       150\n",
      "           3       0.70      0.76      0.73       150\n",
      "           4       0.74      0.69      0.71       150\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       750\n",
      "   macro avg       0.71      0.71      0.71       750\n",
      "weighted avg       0.71      0.71      0.71       750\n",
      " samples avg       0.71      0.71      0.71       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forward(x_train_all_features, y_train,  x_test_all_features, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dae48518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(train, ytrain, test, ytest):\n",
    "    total_feature = train.shape[1]\n",
    "    feature_per_channel = total_feature//64\n",
    "    channel = []\n",
    "    tempfeatures, vtemp = train, test\n",
    "    feature_size = total_feature - feature_per_channel\n",
    "    prev_acc = model(tempfeatures, ytrain, vtemp, ytest)\n",
    "    while feature_size>0:\n",
    "        aaa = [feature_size+i for i in range(feature_per_channel)]\n",
    "        temppp = np.delete(tempfeatures, aaa, axis=1)\n",
    "        vtemppp = np.delete(vtemp, aaa, axis=1)\n",
    "        cuacc = model(temppp, ytrain, vtemppp, ytest)\n",
    "#         print('current accuracy: '+str(cuacc))\n",
    "        if cuacc>=prev_acc:\n",
    "            tempfeatures = temppp\n",
    "            vtemp = vtemppp\n",
    "            channel.append(feature_size//feature_per_channel)\n",
    "#             print('previous accuracy: '+str(prev_acc))\n",
    "            prev_acc = cuacc\n",
    "            feature_size -=feature_per_channel\n",
    "        else:\n",
    "            feature_size -=feature_per_channel\n",
    "    ch_names = [channels_names[i] for i in channel]\n",
    "    print(f\"Top channel : {len(channel)} \\n {ch_names}\")\n",
    "    knnclf(tempfeatures, ytrain, vtemp, ytest)\n",
    "    return tempfeatures, vtemp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e6f3d6",
   "metadata": {},
   "source": [
    "# Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "79cf0525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 19 \n",
      " ['PO8', 'P6', 'P1', 'TP8', 'CP4', 'C6', 'C2', 'C1', 'FT7', 'F6', 'F5', 'AF3', 'AF7', 'O2', 'P8', 'Pz', 'P3', 'P7', 'F3']\n",
      "Accuracy: 0.752\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       150\n",
      "           1       0.70      0.72      0.71       150\n",
      "           2       0.80      0.78      0.79       150\n",
      "           3       0.74      0.77      0.76       150\n",
      "           4       0.78      0.72      0.75       150\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       750\n",
      "   macro avg       0.75      0.75      0.75       750\n",
      "weighted avg       0.75      0.75      0.75       750\n",
      " samples avg       0.75      0.75      0.75       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "backward(x_train_temp, y_train,  x_test_temp, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc51f271",
   "metadata": {},
   "source": [
    "# Statistical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f04a04b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 16 \n",
      " ['PO8', 'POz', 'PO3', 'P6', 'P5', 'FT7', 'F6', 'F5', 'AF8', 'AF3', 'O2', 'P8', 'TP10', 'CP5', 'F8', 'F3']\n",
      "Accuracy: 0.616\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.63       150\n",
      "           1       0.58      0.58      0.58       150\n",
      "           2       0.65      0.64      0.64       150\n",
      "           3       0.58      0.56      0.57       150\n",
      "           4       0.65      0.65      0.65       150\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       750\n",
      "   macro avg       0.62      0.62      0.62       750\n",
      "weighted avg       0.62      0.62      0.62       750\n",
      " samples avg       0.62      0.62      0.62       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "backward(x_train_stat, y_train,  x_test_stat, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b717e453",
   "metadata": {},
   "source": [
    "# Spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4d943565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 11 \n",
      " ['PO8', 'PO4', 'P6', 'P2', 'P5', 'TP8', 'TP7', 'FT10', 'F2', 'Pz', 'P3']\n",
      "Accuracy: 0.4493333333333333\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.47      0.48       150\n",
      "           1       0.43      0.45      0.44       150\n",
      "           2       0.47      0.45      0.46       150\n",
      "           3       0.41      0.44      0.43       150\n",
      "           4       0.46      0.45      0.45       150\n",
      "\n",
      "   micro avg       0.45      0.45      0.45       750\n",
      "   macro avg       0.45      0.45      0.45       750\n",
      "weighted avg       0.45      0.45      0.45       750\n",
      " samples avg       0.45      0.45      0.45       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "backward(x_train_spect, y_train,  x_test_spect, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78580fd4",
   "metadata": {},
   "source": [
    "# stat_spect features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5622d1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 19 \n",
      " ['PO8', 'PO4', 'P6', 'P2', 'P5', 'TP8', 'C6', 'FC4', 'O1', 'PO9', 'Pz', 'CP2', 'T8', 'F8', 'F4', 'Fz', 'F3', 'F7', 'Fp2']\n",
      "Accuracy: 0.44666666666666666\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.48      0.47       150\n",
      "           1       0.45      0.45      0.45       150\n",
      "           2       0.44      0.42      0.43       150\n",
      "           3       0.41      0.43      0.42       150\n",
      "           4       0.48      0.45      0.46       150\n",
      "\n",
      "   micro avg       0.45      0.45      0.45       750\n",
      "   macro avg       0.45      0.45      0.45       750\n",
      "weighted avg       0.45      0.45      0.45       750\n",
      " samples avg       0.45      0.45      0.45       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "backward(x_train_stat_spect, y_train,  x_test_stat_spect, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2104425",
   "metadata": {},
   "source": [
    "# Temp_spect feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "00a53a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 11 \n",
      " ['PO8', 'PO4', 'PO3', 'P6', 'P2', 'P5', 'TP8', 'TP7', 'P8', 'Pz', 'TP9']\n",
      "Accuracy: 0.452\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.48      0.48       150\n",
      "           1       0.44      0.47      0.45       150\n",
      "           2       0.46      0.44      0.45       150\n",
      "           3       0.42      0.42      0.42       150\n",
      "           4       0.46      0.45      0.46       150\n",
      "\n",
      "   micro avg       0.45      0.45      0.45       750\n",
      "   macro avg       0.45      0.45      0.45       750\n",
      "weighted avg       0.45      0.45      0.45       750\n",
      " samples avg       0.45      0.45      0.45       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "backward(x_train_temp_spect, y_train,  x_test_temp_spect, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a1b76",
   "metadata": {},
   "source": [
    "# Stat_Temp feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "77e781d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 47 \n",
      " ['PO8', 'P6', 'P5', 'C1', 'C5', 'FT10', 'FT8', 'FC4', 'FC3', 'FT7', 'FT9', 'F6', 'F2', 'F1', 'F5', 'AF8', 'AF3', 'AF7', 'PO10', 'O2', 'Oz', 'O1', 'P8', 'P4', 'Pz', 'P3', 'P7', 'TP10', 'CP2', 'CP1', 'CP5', 'TP9', 'T8', 'C4', 'Cz', 'C3', 'T7', 'FC6', 'FC2', 'FC1', 'FC5', 'F8', 'F4', 'Fz', 'F3', 'F7', 'Fp2']\n",
      "Accuracy: 0.7293333333333333\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73       150\n",
      "           1       0.66      0.71      0.68       150\n",
      "           2       0.80      0.75      0.77       150\n",
      "           3       0.72      0.78      0.75       150\n",
      "           4       0.75      0.67      0.71       150\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       750\n",
      "   macro avg       0.73      0.73      0.73       750\n",
      "weighted avg       0.73      0.73      0.73       750\n",
      " samples avg       0.73      0.73      0.73       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "backward(x_train_stat_temp, y_train,  x_test_stat_temp, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d03729",
   "metadata": {},
   "source": [
    "# All Spect,temp, stat feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2c66a6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 19 \n",
      " ['PO8', 'PO4', 'PO3', 'P6', 'P1', 'P5', 'CPz', 'TP7', 'O2', 'Oz', 'TP10', 'FC1', 'FC5', 'F8', 'F4', 'Fz', 'F3', 'F7', 'Fp2']\n",
      "Accuracy: 0.45466666666666666\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.47      0.48       150\n",
      "           1       0.44      0.46      0.45       150\n",
      "           2       0.46      0.45      0.45       150\n",
      "           3       0.43      0.43      0.43       150\n",
      "           4       0.47      0.47      0.47       150\n",
      "\n",
      "   micro avg       0.45      0.45      0.45       750\n",
      "   macro avg       0.46      0.45      0.45       750\n",
      "weighted avg       0.46      0.45      0.45       750\n",
      " samples avg       0.45      0.45      0.45       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "backward(x_train_all_features, y_train,  x_test_all_features, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b5a787e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ffba114e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 19 \n",
      " ['PO8', 'P6', 'P1', 'TP8', 'CP4', 'C6', 'C2', 'C1', 'FT7', 'F6', 'F5', 'AF3', 'AF7', 'O2', 'P8', 'Pz', 'P3', 'P7', 'F3']\n",
      "Accuracy: 0.752\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       150\n",
      "           1       0.70      0.72      0.71       150\n",
      "           2       0.80      0.78      0.79       150\n",
      "           3       0.74      0.77      0.76       150\n",
      "           4       0.78      0.72      0.75       150\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       750\n",
      "   macro avg       0.75      0.75      0.75       750\n",
      "weighted avg       0.75      0.75      0.75       750\n",
      " samples avg       0.75      0.75      0.75       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teamp_train, temp_test = backward(x_train_temp, y_train,  x_test_temp, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "63cefb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcatempfeatures = teamp_train.tolist()\n",
    "pcatemp = temp_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "85adc680",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pcatempfeatures\n",
    "data.extend(pcatemp)\n",
    "\n",
    "kpca = KernelPCA(n_components=60)\n",
    "kpca.fit(data)\n",
    "\n",
    "X = kpca.transform(teamp_train)\n",
    "\n",
    "vX = kpca.transform(temp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c4720023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7506666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       150\n",
      "           1       0.70      0.72      0.71       150\n",
      "           2       0.80      0.78      0.79       150\n",
      "           3       0.73      0.77      0.75       150\n",
      "           4       0.78      0.71      0.74       150\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       750\n",
      "   macro avg       0.75      0.75      0.75       750\n",
      "weighted avg       0.75      0.75      0.75       750\n",
      " samples avg       0.75      0.75      0.75       750\n",
      "\n",
      "[[115  10   5  14   6]\n",
      " [ 17 108  11   5   9]\n",
      " [  5  11 117  12   5]\n",
      " [  7  13   3 116  11]\n",
      " [ 10  12  10  11 107]]\n"
     ]
    }
   ],
   "source": [
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(X, y_train)\n",
    "y_pred = kclf.predict(vX)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix([np.argmax(a) for a in y_test], [np.argmax(j) for j in y_pred]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f815088",
   "metadata": {},
   "source": [
    "# Different machine learning algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "58d9c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain = np.array([np.argmax(a) for a in y_train])\n",
    "Ytest = np.array([np.argmax(a) for a in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5be04055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.712\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.67      0.67       150\n",
      "           1       0.66      0.69      0.68       150\n",
      "           2       0.77      0.72      0.74       150\n",
      "           3       0.70      0.77      0.73       150\n",
      "           4       0.76      0.71      0.74       150\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       750\n",
      "   macro avg       0.71      0.71      0.71       750\n",
      "weighted avg       0.71      0.71      0.71       750\n",
      " samples avg       0.71      0.71      0.71       750\n",
      "\n",
      "[[100  13   8  19  10]\n",
      " [ 19 104   9   8  10]\n",
      " [  8  14 108  15   5]\n",
      " [  9  13   5 115   8]\n",
      " [ 11  14  10   8 107]]\n"
     ]
    }
   ],
   "source": [
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(x_train_temp, y_train)\n",
    "y_pred = kclf.predict(x_test_temp)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix([np.argmax(a) for a in y_test], [np.argmax(j) for j in y_pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3132c83a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "08029e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.26266666666666666\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.29      0.29       150\n",
      "           1       0.26      0.31      0.28       150\n",
      "           2       0.23      0.18      0.20       150\n",
      "           3       0.25      0.26      0.25       150\n",
      "           4       0.28      0.28      0.28       150\n",
      "\n",
      "    accuracy                           0.26       750\n",
      "   macro avg       0.26      0.26      0.26       750\n",
      "weighted avg       0.26      0.26      0.26       750\n",
      "\n",
      "[[43 34 23 27 23]\n",
      " [27 46 19 33 25]\n",
      " [25 31 27 26 41]\n",
      " [35 33 24 39 19]\n",
      " [20 33 22 33 42]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97450\\anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lrc = LogisticRegression()\n",
    "lrc.fit(teamp_train, Ytrain)\n",
    "y_pred = lrc.predict(temp_test)\n",
    "print(\"Accuracy:\", accuracy_score(Ytest, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(Ytest, y_pred))\n",
    "print(confusion_matrix(Ytest, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fa10475b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.28\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.28      0.28       150\n",
      "           1       0.31      0.37      0.34       150\n",
      "           2       0.27      0.19      0.22       150\n",
      "           3       0.27      0.31      0.29       150\n",
      "           4       0.27      0.25      0.26       150\n",
      "\n",
      "    accuracy                           0.28       750\n",
      "   macro avg       0.28      0.28      0.28       750\n",
      "weighted avg       0.28      0.28      0.28       750\n",
      "\n",
      "[[42 32 22 32 22]\n",
      " [25 55 19 28 23]\n",
      " [22 32 29 26 41]\n",
      " [35 35 17 46 17]\n",
      " [27 24 22 39 38]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97450\\anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lrc.fit(x_train_temp, Ytrain)\n",
    "y_pred = lrc.predict(x_test_temp)\n",
    "print(\"Accuracy:\", accuracy_score(Ytest, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(Ytest, y_pred))\n",
    "print(confusion_matrix(Ytest, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1a06783a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.31066666666666665\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.31      0.32       150\n",
      "           1       0.29      0.31      0.30       150\n",
      "           2       0.33      0.35      0.34       150\n",
      "           3       0.29      0.31      0.30       150\n",
      "           4       0.32      0.28      0.30       150\n",
      "\n",
      "    accuracy                           0.31       750\n",
      "   macro avg       0.31      0.31      0.31       750\n",
      "weighted avg       0.31      0.31      0.31       750\n",
      "\n",
      "[[47 28 23 32 20]\n",
      " [28 46 31 22 23]\n",
      " [21 23 52 31 23]\n",
      " [25 27 27 46 25]\n",
      " [25 32 24 27 42]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "lrc = DecisionTreeClassifier()\n",
    "lrc.fit(teamp_train, Ytrain)\n",
    "y_pred = lrc.predict(temp_test)\n",
    "print(\"Accuracy:\", accuracy_score(Ytest, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(Ytest, y_pred))\n",
    "print(confusion_matrix(Ytest, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bc2d91d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3453333333333333\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.37      0.36       150\n",
      "           1       0.32      0.33      0.33       150\n",
      "           2       0.37      0.41      0.39       150\n",
      "           3       0.30      0.29      0.30       150\n",
      "           4       0.39      0.33      0.36       150\n",
      "\n",
      "    accuracy                           0.35       750\n",
      "   macro avg       0.35      0.35      0.34       750\n",
      "weighted avg       0.35      0.35      0.34       750\n",
      "\n",
      "[[55 28 19 31 17]\n",
      " [29 49 20 23 29]\n",
      " [19 29 61 22 19]\n",
      " [33 28 31 44 14]\n",
      " [21 17 35 27 50]]\n"
     ]
    }
   ],
   "source": [
    "lrc.fit(x_train_temp, Ytrain)\n",
    "y_pred = lrc.predict(x_test_temp)\n",
    "print(\"Accuracy:\", accuracy_score(Ytest, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(Ytest, y_pred))\n",
    "print(confusion_matrix(Ytest, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c0703a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4746666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.49      0.48       150\n",
      "           1       0.43      0.44      0.43       150\n",
      "           2       0.49      0.49      0.49       150\n",
      "           3       0.49      0.51      0.50       150\n",
      "           4       0.52      0.43      0.47       150\n",
      "\n",
      "    accuracy                           0.47       750\n",
      "   macro avg       0.48      0.47      0.47       750\n",
      "weighted avg       0.48      0.47      0.47       750\n",
      "\n",
      "[[74 22 19 18 17]\n",
      " [29 66 16 24 15]\n",
      " [16 21 74 23 16]\n",
      " [17 21 22 77 13]\n",
      " [25 25 20 15 65]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "lrc = RandomForestClassifier()\n",
    "lrc.fit(teamp_train, Ytrain)\n",
    "y_pred = lrc.predict(temp_test)\n",
    "print(\"Accuracy:\", accuracy_score(Ytest, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(Ytest, y_pred))\n",
    "print(confusion_matrix(Ytest, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3d4c9b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4666666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.47      0.48       150\n",
      "           1       0.41      0.47      0.44       150\n",
      "           2       0.48      0.49      0.49       150\n",
      "           3       0.46      0.49      0.47       150\n",
      "           4       0.52      0.41      0.46       150\n",
      "\n",
      "    accuracy                           0.47       750\n",
      "   macro avg       0.47      0.47      0.47       750\n",
      "weighted avg       0.47      0.47      0.47       750\n",
      "\n",
      "[[71 21 13 30 15]\n",
      " [18 71 20 26 15]\n",
      " [17 28 74 18 13]\n",
      " [17 25 21 73 14]\n",
      " [23 28 25 13 61]]\n"
     ]
    }
   ],
   "source": [
    "lrc.fit(x_train_temp, Ytrain)\n",
    "y_pred = lrc.predict(x_test_temp)\n",
    "print(\"Accuracy:\", accuracy_score(Ytest, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(Ytest, y_pred))\n",
    "print(confusion_matrix(Ytest, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "634fa6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49866666666666665\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.49      0.52       150\n",
      "           1       0.46      0.49      0.48       150\n",
      "           2       0.51      0.55      0.53       150\n",
      "           3       0.44      0.48      0.46       150\n",
      "           4       0.54      0.48      0.51       150\n",
      "\n",
      "    accuracy                           0.50       750\n",
      "   macro avg       0.50      0.50      0.50       750\n",
      "weighted avg       0.50      0.50      0.50       750\n",
      "\n",
      "[[73 19 15 28 15]\n",
      " [14 74 18 26 18]\n",
      " [ 9 22 83 21 15]\n",
      " [18 24 23 72 13]\n",
      " [19 21 23 15 72]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "lrc = AdaBoostClassifier(RandomForestClassifier(),n_estimators=10,learning_rate=0.6)\n",
    "lrc.fit(teamp_train, Ytrain)\n",
    "y_pred = lrc.predict(temp_test)\n",
    "print(\"Accuracy:\", accuracy_score(Ytest, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(Ytest, y_pred))\n",
    "print(confusion_matrix(Ytest, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "09d704d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5066666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.52      0.51       150\n",
      "           1       0.48      0.50      0.49       150\n",
      "           2       0.54      0.53      0.54       150\n",
      "           3       0.49      0.53      0.51       150\n",
      "           4       0.53      0.45      0.49       150\n",
      "\n",
      "    accuracy                           0.51       750\n",
      "   macro avg       0.51      0.51      0.51       750\n",
      "weighted avg       0.51      0.51      0.51       750\n",
      "\n",
      "[[78 19 13 25 15]\n",
      " [22 75 17 22 14]\n",
      " [15 18 79 19 19]\n",
      " [20 26 11 80 13]\n",
      " [23 18 25 16 68]]\n"
     ]
    }
   ],
   "source": [
    "lrc.fit(x_train_temp, Ytrain)\n",
    "y_pred = lrc.predict(x_test_temp)\n",
    "print(\"Accuracy:\", accuracy_score(Ytest, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(Ytest, y_pred))\n",
    "print(confusion_matrix(Ytest, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "68261d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42133333333333334\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.40      0.42       150\n",
      "           1       0.41      0.38      0.39       150\n",
      "           2       0.47      0.45      0.46       150\n",
      "           3       0.41      0.48      0.44       150\n",
      "           4       0.39      0.40      0.39       150\n",
      "\n",
      "    accuracy                           0.42       750\n",
      "   macro avg       0.42      0.42      0.42       750\n",
      "weighted avg       0.42      0.42      0.42       750\n",
      "\n",
      "[[60 24 23 26 17]\n",
      " [29 57 12 27 25]\n",
      " [16 18 67 23 26]\n",
      " [10 21 21 72 26]\n",
      " [24 19 21 26 60]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "lrc=BaggingClassifier(RandomForestClassifier(),max_samples=0.5,max_features=1.0,n_estimators=10)\n",
    "lrc.fit(teamp_train, Ytrain)\n",
    "y_pred = lrc.predict(temp_test)\n",
    "print(\"Accuracy:\", accuracy_score(Ytest, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(Ytest, y_pred))\n",
    "print(confusion_matrix(Ytest, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "57baed26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4093333333333333\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.46      0.44       150\n",
      "           1       0.40      0.37      0.39       150\n",
      "           2       0.45      0.41      0.43       150\n",
      "           3       0.41      0.45      0.43       150\n",
      "           4       0.37      0.35      0.36       150\n",
      "\n",
      "    accuracy                           0.41       750\n",
      "   macro avg       0.41      0.41      0.41       750\n",
      "weighted avg       0.41      0.41      0.41       750\n",
      "\n",
      "[[69 18 19 24 20]\n",
      " [29 56 14 27 24]\n",
      " [23 25 62 19 21]\n",
      " [21 17 19 68 25]\n",
      " [23 24 25 26 52]]\n"
     ]
    }
   ],
   "source": [
    "lrc.fit(x_train_temp, Ytrain)\n",
    "y_pred = lrc.predict(x_test_temp)\n",
    "print(\"Accuracy:\", accuracy_score(Ytest, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(Ytest, y_pred))\n",
    "print(confusion_matrix(Ytest, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2be172d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97450\\anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\97450\\anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.532\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.65      0.62       150\n",
      "           1       0.39      0.70      0.50       150\n",
      "           2       0.67      0.49      0.56       150\n",
      "           3       0.55      0.52      0.53       150\n",
      "           4       0.69      0.30      0.42       150\n",
      "\n",
      "    accuracy                           0.53       750\n",
      "   macro avg       0.58      0.53      0.53       750\n",
      "weighted avg       0.58      0.53      0.53       750\n",
      "\n",
      "[[ 98  28   7  14   3]\n",
      " [ 19 105   9  12   5]\n",
      " [ 13  42  73  15   7]\n",
      " [ 14  46   7  78   5]\n",
      " [ 20  48  13  24  45]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "lrc=VotingClassifier(estimators=[('kclf',kclf),('lrc',LogisticRegression()), ('rf',RandomForestClassifier()),\n",
    "                                 ('svm',LinearSVC()), ('dtc', DecisionTreeClassifier())], voting='hard')\n",
    "lrc.fit(teamp_train, Ytrain)\n",
    "y_pred = lrc.predict(temp_test)\n",
    "print(\"Accuracy:\", accuracy_score(Ytest, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(Ytest, y_pred))\n",
    "print(confusion_matrix(Ytest, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "01b8b563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97450\\anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\97450\\anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.576\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.61      0.58       150\n",
      "           1       0.56      0.52      0.54       150\n",
      "           2       0.71      0.53      0.61       150\n",
      "           3       0.47      0.79      0.59       150\n",
      "           4       0.79      0.43      0.55       150\n",
      "\n",
      "    accuracy                           0.58       750\n",
      "   macro avg       0.62      0.58      0.57       750\n",
      "weighted avg       0.62      0.58      0.57       750\n",
      "\n",
      "[[ 92  12   3  40   3]\n",
      " [ 31  78  10  25   6]\n",
      " [ 11  22  80  29   8]\n",
      " [ 14  11   7 118   0]\n",
      " [ 18  16  12  40  64]]\n"
     ]
    }
   ],
   "source": [
    "lrc.fit(x_train_temp, Ytrain)\n",
    "y_pred = lrc.predict(x_test_temp)\n",
    "print(\"Accuracy:\", accuracy_score(Ytest, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(Ytest, y_pred))\n",
    "print(confusion_matrix(Ytest, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2c6c1577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.31733333333333336\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.18      0.26       150\n",
      "           1       0.42      0.27      0.33       150\n",
      "           2       0.30      0.65      0.41       150\n",
      "           3       0.38      0.04      0.07       150\n",
      "           4       0.26      0.45      0.33       150\n",
      "\n",
      "    accuracy                           0.32       750\n",
      "   macro avg       0.37      0.32      0.28       750\n",
      "weighted avg       0.37      0.32      0.28       750\n",
      "\n",
      "[[27 17 50  1 55]\n",
      " [ 7 41 55  5 42]\n",
      " [ 6  8 97  1 38]\n",
      " [ 6 19 66  6 53]\n",
      " [10 13 57  3 67]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(150,100,50), max_iter=300, activation = 'relu',solver='adam',random_state=1)\n",
    "clf.fit(teamp_train, Ytrain)\n",
    "y_pred = clf.predict(temp_test)\n",
    "print(\"Accuracy:\", accuracy_score(Ytest, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(Ytest, y_pred))\n",
    "print(confusion_matrix(Ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "419a28eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.252\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.02      0.04       150\n",
      "           1       0.50      0.01      0.03       150\n",
      "           2       0.23      0.41      0.30       150\n",
      "           3       0.24      0.57      0.34       150\n",
      "           4       0.31      0.24      0.27       150\n",
      "\n",
      "    accuracy                           0.25       750\n",
      "   macro avg       0.34      0.25      0.19       750\n",
      "weighted avg       0.34      0.25      0.19       750\n",
      "\n",
      "[[ 3  0 50 84 13]\n",
      " [ 2  2 61 69 16]\n",
      " [ 1  1 62 57 29]\n",
      " [ 1  1 41 86 21]\n",
      " [ 0  0 56 58 36]]\n"
     ]
    }
   ],
   "source": [
    "clf.fit(x_train_temp, Ytrain)\n",
    "y_pred = clf.predict(x_test_temp)\n",
    "print(\"Accuracy:\", accuracy_score(Ytest, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(Ytest, y_pred))\n",
    "print(confusion_matrix(Ytest, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ea3d391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "390fe168",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate((Ytrain, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fc233457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5250,)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1e10c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((teamp_train, temp_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fd39d6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5250, 540)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8c802b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scores = cross_val_score(kclf, x, y, scoring='accuracy',\n",
    "                         cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1dc331b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7180952380952381"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c97e7b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7657142857142857"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1ae96879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6952380952380952"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "54cf7a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6952381 , 0.74285714, 0.70095238, 0.72571429, 0.6952381 ,\n",
       "       0.76571429, 0.6952381 , 0.72380952, 0.70095238, 0.7352381 ])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e4d83362",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((x_train_temp, x_test_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a1fa7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scores = cross_val_score(kclf, x, y, scoring='accuracy',\n",
    "                         cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "58d45258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.715047619047619"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "18e2c287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7542857142857143"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "52b51bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6685714285714286"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f2495",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "bbaad4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top channel : 19 \n",
      " ['PO8', 'P6', 'P1', 'TP8', 'CP4', 'C6', 'C2', 'C1', 'FT7', 'F6', 'F5', 'AF3', 'AF7', 'O2', 'P8', 'Pz', 'P3', 'P7', 'F3']\n",
      "Accuracy: 0.752\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       150\n",
      "           1       0.70      0.72      0.71       150\n",
      "           2       0.80      0.78      0.79       150\n",
      "           3       0.74      0.77      0.76       150\n",
      "           4       0.78      0.72      0.75       150\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       750\n",
      "   macro avg       0.75      0.75      0.75       750\n",
      "weighted avg       0.75      0.75      0.75       750\n",
      " samples avg       0.75      0.75      0.75       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, test = backward(x_train_temp, y_train,  x_test_temp, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5f9f0aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.752\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       150\n",
      "           1       0.70      0.72      0.71       150\n",
      "           2       0.80      0.78      0.79       150\n",
      "           3       0.74      0.77      0.76       150\n",
      "           4       0.78      0.72      0.75       150\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       750\n",
      "   macro avg       0.75      0.75      0.75       750\n",
      "weighted avg       0.75      0.75      0.75       750\n",
      " samples avg       0.75      0.75      0.75       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train, y_train)\n",
    "y_pred = kclf.predict(test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix([np.argmax(a) for a in y_test], [np.argmax(j) for j in y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a3827c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "cf_matrix = cm*100/150\n",
    "plt.figure(figsize=(12, 9))\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap=\"Blues\")\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['hello', 'help me', 'stop', 'thank you', 'yes'])\n",
    "ax.yaxis.set_ticklabels(['hello', 'help me', 'stop', 'thank you', 'yes'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "\n",
    "plt.savefig('confusion_matrix.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "4c62a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_1 = [\"FC5\", \"CP5\", \"F5\", \"FT7\", \"FC3\", \"TP7\", \"CP3\", \"P5\"]\n",
    "# 1) Inferring imagined speech using EEG signals a new approach using Riemannian manifold features\n",
    "# 2) Multiclass Classification of Word Imagination Speech With Hybrid Connectivity Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "23e57e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_index = []\n",
    "for idx, i in enumerate(channels_names):\n",
    "    if i in paper_1:\n",
    "        channel_index.append(idx)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "338ddb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_channels_impl(channel_index, train, y_train, test, y_test):\n",
    "#     tempfeatures, vtemp = np.array()\n",
    "    \n",
    "    total_feature = train.shape[1]\n",
    "    feature_per_channel = total_feature//64\n",
    "    induces = []\n",
    "    for induce in channel_index:\n",
    "        induce = induce*feature_per_channel\n",
    "        induces.extend([induce+i for i in range(feature_per_channel)])\n",
    "    return train[:,induces], test[:,induces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "aca5fc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Spect Accuracy: 0.26\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.28      0.29       150\n",
      "           1       0.24      0.22      0.23       150\n",
      "           2       0.27      0.27      0.27       150\n",
      "           3       0.28      0.31      0.29       150\n",
      "           4       0.22      0.22      0.22       150\n",
      "\n",
      "   micro avg       0.26      0.26      0.26       750\n",
      "   macro avg       0.26      0.26      0.26       750\n",
      "weighted avg       0.26      0.26      0.26       750\n",
      " samples avg       0.26      0.26      0.26       750\n",
      "\n",
      " Stat Accuracy: 0.39866666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.35      0.34       150\n",
      "           1       0.40      0.39      0.39       150\n",
      "           2       0.40      0.38      0.39       150\n",
      "           3       0.41      0.43      0.42       150\n",
      "           4       0.46      0.45      0.45       150\n",
      "\n",
      "   micro avg       0.40      0.40      0.40       750\n",
      "   macro avg       0.40      0.40      0.40       750\n",
      "weighted avg       0.40      0.40      0.40       750\n",
      " samples avg       0.40      0.40      0.40       750\n",
      "\n",
      " Temp Accuracy: 0.47333333333333333\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.51      0.48       150\n",
      "           1       0.40      0.41      0.40       150\n",
      "           2       0.49      0.45      0.47       150\n",
      "           3       0.53      0.52      0.52       150\n",
      "           4       0.50      0.47      0.49       150\n",
      "\n",
      "   micro avg       0.47      0.47      0.47       750\n",
      "   macro avg       0.47      0.47      0.47       750\n",
      "weighted avg       0.47      0.47      0.47       750\n",
      " samples avg       0.47      0.47      0.47       750\n",
      "\n",
      " Spect Stat Accuracy: 0.30133333333333334\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.34      0.34       150\n",
      "           1       0.28      0.32      0.30       150\n",
      "           2       0.26      0.23      0.25       150\n",
      "           3       0.32      0.31      0.31       150\n",
      "           4       0.31      0.31      0.31       150\n",
      "\n",
      "   micro avg       0.30      0.30      0.30       750\n",
      "   macro avg       0.30      0.30      0.30       750\n",
      "weighted avg       0.30      0.30      0.30       750\n",
      " samples avg       0.30      0.30      0.30       750\n",
      "\n",
      " Stat Temp Accuracy: 0.6066666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.58      0.58       150\n",
      "           1       0.56      0.57      0.57       150\n",
      "           2       0.64      0.59      0.62       150\n",
      "           3       0.60      0.69      0.64       150\n",
      "           4       0.68      0.60      0.64       150\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       750\n",
      "   macro avg       0.61      0.61      0.61       750\n",
      "weighted avg       0.61      0.61      0.61       750\n",
      " samples avg       0.61      0.61      0.61       750\n",
      "\n",
      " Temp Spect Accuracy: 0.28\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.27      0.26       150\n",
      "           1       0.29      0.27      0.28       150\n",
      "           2       0.27      0.27      0.27       150\n",
      "           3       0.28      0.28      0.28       150\n",
      "           4       0.32      0.31      0.31       150\n",
      "\n",
      "   micro avg       0.28      0.28      0.28       750\n",
      "   macro avg       0.28      0.28      0.28       750\n",
      "weighted avg       0.28      0.28      0.28       750\n",
      " samples avg       0.28      0.28      0.28       750\n",
      "\n",
      " All Accuracy: 0.272\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.25      0.25       150\n",
      "           1       0.29      0.30      0.30       150\n",
      "           2       0.26      0.25      0.26       150\n",
      "           3       0.28      0.27      0.28       150\n",
      "           4       0.28      0.29      0.28       150\n",
      "\n",
      "   micro avg       0.27      0.27      0.27       750\n",
      "   macro avg       0.27      0.27      0.27       750\n",
      "weighted avg       0.27      0.27      0.27       750\n",
      " samples avg       0.27      0.27      0.27       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spect\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_spect, y_train,  x_test_spect, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" Spect Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Statistical\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_stat, y_train,  x_test_stat, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" Stat Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_temp, y_train,  x_test_temp, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" Temp Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Spect Stat\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_stat_spect, y_train,  x_test_stat_spect, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" Spect Stat Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Stat Temp\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_stat_temp, y_train,  x_test_stat_temp, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" Stat Temp Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Temp Spect\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_temp_spect, y_train,  x_test_temp_spect, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" Temp Spect Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# All Stat, spect, Temp\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_all_features, y_train,  x_test_all_features, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" All Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "fada4974",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_2 = [\"T7\", \"C5\",\"C3\", \"C1\", \"CP5\", \"FC1\", \"FC3\", \"FC5\", \"FC6\", \"FT7\", \"F1\", \"F3\", \"F5\", \"F7\", \"FT8\", \"TP7\"]\n",
    "# EEG signal classification of imagined speech based on Riemannian distance of correntropy spectral density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f7d99059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 7, 8, 10, 11, 12, 17, 36, 37, 41, 42, 44, 46, 47, 50]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_index = []\n",
    "for idx, i in enumerate(channels_names):\n",
    "    if i in paper_2:\n",
    "        channel_index.append(idx)\n",
    "    else:\n",
    "        pass\n",
    "channel_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "400b8d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Spect Accuracy: 0.33066666666666666\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.29       150\n",
      "           1       0.30      0.32      0.31       150\n",
      "           2       0.30      0.27      0.28       150\n",
      "           3       0.35      0.38      0.36       150\n",
      "           4       0.40      0.41      0.41       150\n",
      "\n",
      "   micro avg       0.33      0.33      0.33       750\n",
      "   macro avg       0.33      0.33      0.33       750\n",
      "weighted avg       0.33      0.33      0.33       750\n",
      " samples avg       0.33      0.33      0.33       750\n",
      "\n",
      " Stat Accuracy: 0.4666666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.45      0.46       150\n",
      "           1       0.47      0.47      0.47       150\n",
      "           2       0.51      0.47      0.49       150\n",
      "           3       0.41      0.47      0.44       150\n",
      "           4       0.49      0.48      0.48       150\n",
      "\n",
      "   micro avg       0.47      0.47      0.47       750\n",
      "   macro avg       0.47      0.47      0.47       750\n",
      "weighted avg       0.47      0.47      0.47       750\n",
      " samples avg       0.47      0.47      0.47       750\n",
      "\n",
      " Temp Accuracy: 0.624\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65       150\n",
      "           1       0.60      0.62      0.61       150\n",
      "           2       0.62      0.59      0.60       150\n",
      "           3       0.61      0.64      0.63       150\n",
      "           4       0.63      0.63      0.63       150\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       750\n",
      "   macro avg       0.62      0.62      0.62       750\n",
      "weighted avg       0.62      0.62      0.62       750\n",
      " samples avg       0.62      0.62      0.62       750\n",
      "\n",
      " Spect Stat Accuracy: 0.3373333333333333\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.35      0.35       150\n",
      "           1       0.33      0.34      0.33       150\n",
      "           2       0.34      0.35      0.34       150\n",
      "           3       0.33      0.31      0.32       150\n",
      "           4       0.35      0.33      0.34       150\n",
      "\n",
      "   micro avg       0.34      0.34      0.34       750\n",
      "   macro avg       0.34      0.34      0.34       750\n",
      "weighted avg       0.34      0.34      0.34       750\n",
      " samples avg       0.34      0.34      0.34       750\n",
      "\n",
      " Stat Temp Accuracy: 0.4653333333333333\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.42      0.42       150\n",
      "           1       0.42      0.41      0.42       150\n",
      "           2       0.49      0.49      0.49       150\n",
      "           3       0.54      0.55      0.54       150\n",
      "           4       0.46      0.46      0.46       150\n",
      "\n",
      "   micro avg       0.47      0.47      0.47       750\n",
      "   macro avg       0.46      0.47      0.47       750\n",
      "weighted avg       0.46      0.47      0.47       750\n",
      " samples avg       0.47      0.47      0.47       750\n",
      "\n",
      " Temp Spect Accuracy: 0.32133333333333336\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.31      0.32       150\n",
      "           1       0.30      0.31      0.30       150\n",
      "           2       0.33      0.37      0.35       150\n",
      "           3       0.31      0.28      0.29       150\n",
      "           4       0.33      0.34      0.34       150\n",
      "\n",
      "   micro avg       0.32      0.32      0.32       750\n",
      "   macro avg       0.32      0.32      0.32       750\n",
      "weighted avg       0.32      0.32      0.32       750\n",
      " samples avg       0.32      0.32      0.32       750\n",
      "\n",
      " All Accuracy: 0.332\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.41      0.38       150\n",
      "           1       0.35      0.36      0.35       150\n",
      "           2       0.36      0.32      0.34       150\n",
      "           3       0.28      0.27      0.28       150\n",
      "           4       0.32      0.30      0.31       150\n",
      "\n",
      "   micro avg       0.33      0.33      0.33       750\n",
      "   macro avg       0.33      0.33      0.33       750\n",
      "weighted avg       0.33      0.33      0.33       750\n",
      " samples avg       0.33      0.33      0.33       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spect\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_spect, y_train,  x_test_spect, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" Spect Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Statistical\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_stat, y_train,  x_test_stat, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" Stat Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_temp, y_train,  x_test_temp, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" Temp Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Spect Stat\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_stat_spect, y_train,  x_test_stat_spect, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" Spect Stat Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Stat Temp\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_stat_temp, y_train,  x_test_stat_temp, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" Stat Temp Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Temp Spect\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_temp_spect, y_train,  x_test_temp_spect, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" Temp Spect Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# All Stat, spect, Temp\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_all_features, y_train,  x_test_all_features, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" All Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "3085e521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_3 = [\"T7\", \"T8\", \"TP9\", \"TP10\", \"F3\", \"F4\", \"F7\",\"F8\", \"FC1\",\"FC2\",\"FC5\",\"Fp1\", \"Fp2\", \"FT9\", \"FT10\", \"Fz\"]\n",
    "len(paper_3)\n",
    "# Continuous Silent Speech Recognition using EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "e71bdb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 15, 16, 21, 40, 45]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_index = []\n",
    "for idx, i in enumerate(channels_names):\n",
    "    if i in paper_3:\n",
    "        channel_index.append(idx)\n",
    "    else:\n",
    "        pass\n",
    "channel_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e979a8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Spect Accuracy: 0.3506666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.33      0.32       150\n",
      "           1       0.35      0.32      0.33       150\n",
      "           2       0.36      0.39      0.37       150\n",
      "           3       0.39      0.33      0.36       150\n",
      "           4       0.35      0.38      0.36       150\n",
      "\n",
      "   micro avg       0.35      0.35      0.35       750\n",
      "   macro avg       0.35      0.35      0.35       750\n",
      "weighted avg       0.35      0.35      0.35       750\n",
      " samples avg       0.35      0.35      0.35       750\n",
      "\n",
      " Stat Accuracy: 0.4826666666666667\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.52      0.50       150\n",
      "           1       0.48      0.48      0.48       150\n",
      "           2       0.50      0.49      0.49       150\n",
      "           3       0.47      0.45      0.46       150\n",
      "           4       0.50      0.47      0.48       150\n",
      "\n",
      "   micro avg       0.48      0.48      0.48       750\n",
      "   macro avg       0.48      0.48      0.48       750\n",
      "weighted avg       0.48      0.48      0.48       750\n",
      " samples avg       0.48      0.48      0.48       750\n",
      "\n",
      " Temp Accuracy: 0.6333333333333333\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64       150\n",
      "           1       0.56      0.55      0.56       150\n",
      "           2       0.69      0.66      0.67       150\n",
      "           3       0.62      0.63      0.63       150\n",
      "           4       0.70      0.64      0.67       150\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       750\n",
      "   macro avg       0.64      0.63      0.63       750\n",
      "weighted avg       0.64      0.63      0.63       750\n",
      " samples avg       0.63      0.63      0.63       750\n",
      "\n",
      " Spect Stat Accuracy: 0.2773333333333333\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.35      0.33       150\n",
      "           1       0.30      0.33      0.31       150\n",
      "           2       0.29      0.28      0.29       150\n",
      "           3       0.24      0.22      0.23       150\n",
      "           4       0.23      0.21      0.22       150\n",
      "\n",
      "   micro avg       0.28      0.28      0.28       750\n",
      "   macro avg       0.27      0.28      0.28       750\n",
      "weighted avg       0.27      0.28      0.28       750\n",
      " samples avg       0.28      0.28      0.28       750\n",
      "\n",
      " Stat Temp Accuracy: 0.516\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.57      0.56       150\n",
      "           1       0.51      0.49      0.50       150\n",
      "           2       0.51      0.49      0.50       150\n",
      "           3       0.47      0.48      0.48       150\n",
      "           4       0.54      0.54      0.54       150\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       750\n",
      "   macro avg       0.52      0.52      0.52       750\n",
      "weighted avg       0.52      0.52      0.52       750\n",
      " samples avg       0.52      0.52      0.52       750\n",
      "\n",
      " Temp Spect Accuracy: 0.30533333333333335\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.27      0.28       150\n",
      "           1       0.30      0.32      0.31       150\n",
      "           2       0.34      0.37      0.35       150\n",
      "           3       0.31      0.29      0.30       150\n",
      "           4       0.29      0.27      0.28       150\n",
      "\n",
      "   micro avg       0.31      0.31      0.31       750\n",
      "   macro avg       0.30      0.31      0.30       750\n",
      "weighted avg       0.30      0.31      0.30       750\n",
      " samples avg       0.31      0.31      0.31       750\n",
      "\n",
      " All Accuracy: 0.25733333333333336\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.24      0.25       150\n",
      "           1       0.21      0.21      0.21       150\n",
      "           2       0.27      0.26      0.27       150\n",
      "           3       0.31      0.34      0.32       150\n",
      "           4       0.23      0.23      0.23       150\n",
      "\n",
      "   micro avg       0.26      0.26      0.26       750\n",
      "   macro avg       0.26      0.26      0.26       750\n",
      "weighted avg       0.26      0.26      0.26       750\n",
      " samples avg       0.26      0.26      0.26       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spect\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_spect, y_train,  x_test_spect, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" Spect Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Statistical\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_stat, y_train,  x_test_stat, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" Stat Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_temp, y_train,  x_test_temp, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" Temp Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Spect Stat\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_stat_spect, y_train,  x_test_stat_spect, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" Spect Stat Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Stat Temp\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_stat_temp, y_train,  x_test_stat_temp, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" Stat Temp Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Temp Spect\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_temp_spect, y_train,  x_test_temp_spect, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" Temp Spect Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# All Stat, spect, Temp\n",
    "\n",
    "train_temp_s, test_temp_s = paper_channels_impl(channel_index, x_train_all_features, y_train,  x_test_all_features, y_test)\n",
    "kclf = KNeighborsClassifier(n_neighbors=1)\n",
    "kclf.fit(train_temp_s, y_train)\n",
    "y_pred = kclf.predict(test_temp_s)\n",
    "print(\" All Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d7cba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
